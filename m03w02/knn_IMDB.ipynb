{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "K-Nearest Neighbors (KNN) là một trong những thuật toán học máy có giám sát cơ bản. KNN\n",
    "còn được gọi là Lazy Learning, Memory-Based Learning,... Với bước huấn luyện mô hình, chỉ đơn giản\n",
    "là lưu trữ lại giá trị của dữ liệu huấn luyện, vì vậy KNN là phương pháp học máy không tham số\n",
    "(Non-Parametric). Ở bước dự đoán, mô hình sẽ dử dụng các độ đo khoảng cách để tìm các hàng xóm\n",
    "lân cận.\n",
    "\n",
    "Một số độ đo thường được sử dụng trong KNN như:\n",
    "1. Euclidean\n",
    "2. Chebyshev\n",
    "3. Manhattan\n",
    "4. Minkowski\n",
    "\n",
    "Các độ đo này tính toán dữ liệu dự đoán với các điểm dữ liệu khác được lưu trữ trong mô hình huấn\n",
    "luyện. Từ đó xếp hạng và tìm ra K điểm dữ liệu huấn luyện có kết quả gần với dữ liệu dự đoán nhất.\n",
    "Cuối cùng dựa vào phương pháp biểu quyết của các dữ liệu hàng xóm trong tập huấn luyện để đưa ra\n",
    "kết quả dự đoán.\n",
    "\n",
    "![Hình 1: Mô tả quá trình huấn luyện và dự đoán mô hình KNN.](../docs/k-nearest-neighbors.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN được sử dụng rộng rãi cho ứng dụng phân loại (Classification) và dự đoán (Regression) được\n",
    "mô tả như hình sau:\n",
    "\n",
    "![Hình 2: Mô tả quá trình huấn luyện và dự đoán mô hình KNN.](../docs/knn-training.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ứng dụng KNN cho bài toán phân loại văn bản trên bộ dữ liệu đánh giá phim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_datasets' from 'datasets' (c:\\MyAIO\\aio-151-HaiAnh-Exercise\\aio2024\\Lib\\site-packages\\datasets\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_datasets\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_datasets' from 'datasets' (c:\\MyAIO\\aio-151-HaiAnh-Exercise\\aio2024\\Lib\\site-packages\\datasets\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the IMDB dataset\n",
    "imdb = load_datasets(\"imdb\")\n",
    "imdb_train, imdb_test = imdb['train'], imdb['test']\n",
    "\n",
    "# Convert text to vector using BoW\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X_train = vectorizer.fit_transform(imdb_train['text']).toarray()\n",
    "X_test = vectorizer.transform(imdb_test['text']).toarray()\n",
    "y_train = np.array(imdb_train['label'])\n",
    "y_test = np.array(imdb_test['label'])\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "sclaler = StandardScaler()\n",
    "X_train = sclaler.fit_transform(X_train)\n",
    "X_test = sclaler.transform(X_test)\n",
    "\n",
    "# Build KNN Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1, algorithm='ball_tree')\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and Evaluate test set\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
