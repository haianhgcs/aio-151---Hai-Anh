{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOS0tHoSmoJfnmdvv8csLDA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ga2YcfrKWQ-0","executionInfo":{"status":"ok","timestamp":1731419658636,"user_tz":-420,"elapsed":7441,"user":{"displayName":"Anh Nguyen","userId":"14949101190369963696"}},"outputId":"78cb2f1c-b38c-4e2a-9157-c758ee4adbac"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import nltk\n","nltk.download('stopwords')\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer"]},{"cell_type":"code","source":["dataset_path = 'Twitter_Data.csv'\n","df = pd.read_csv(dataset_path)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"hWGhA024ppHM","executionInfo":{"status":"ok","timestamp":1731419658638,"user_tz":-420,"elapsed":32,"user":{"displayName":"Anh Nguyen","userId":"14949101190369963696"}},"outputId":"0b4c0dba-a0c0-46eb-a8d5-9cac6fc31333"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              clean_text  category\n","0      when modi promised “minimum government maximum...      -1.0\n","1      talk all the nonsense and continue all the dra...       0.0\n","2      what did just say vote for modi  welcome bjp t...       1.0\n","3      asking his supporters prefix chowkidar their n...       1.0\n","4      answer who among these the most powerful world...       1.0\n","...                                                  ...       ...\n","57848  and clarify you ardent karyakarta for trs when...       0.0\n","57849  during before announced feat scientists today ...       1.0\n","57850                          why would act helps modi        0.0\n","57851  are with modi and modi with and you are useles...      -1.0\n","57852                                       you and your       NaN\n","\n","[57853 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-d564c000-578d-4b64-9b53-5744db27aac3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_text</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>when modi promised “minimum government maximum...</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>talk all the nonsense and continue all the dra...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>what did just say vote for modi  welcome bjp t...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>asking his supporters prefix chowkidar their n...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>answer who among these the most powerful world...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>57848</th>\n","      <td>and clarify you ardent karyakarta for trs when...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>57849</th>\n","      <td>during before announced feat scientists today ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>57850</th>\n","      <td>why would act helps modi</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>57851</th>\n","      <td>are with modi and modi with and you are useles...</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>57852</th>\n","      <td>you and your</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>57853 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d564c000-578d-4b64-9b53-5744db27aac3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d564c000-578d-4b64-9b53-5744db27aac3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d564c000-578d-4b64-9b53-5744db27aac3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-de7da7c8-cd4c-42c5-bf19-2d6be12fb7b1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de7da7c8-cd4c-42c5-bf19-2d6be12fb7b1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-de7da7c8-cd4c-42c5-bf19-2d6be12fb7b1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_7d39b108-86c6-416d-aa90-481532759611\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_7d39b108-86c6-416d-aa90-481532759611 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 57853,\n  \"fields\": [\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57852,\n        \"samples\": [\n          \"modi rajnath jaitley above the age central govt retirement\",\n          \"has challenged openly number times but our chor never responded chor busy selling tshirts promoting movie started modi channel that shows modi 24x7 \\u2019 all about marketing for our chor \",\n          \"modi loves urdu promoting deal with him first dude \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7808222979186182,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1.0,\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## Xóa missing data:\n","Bộ dữ liệu này có tồn tại một vài hàng chứa giá trị null:"],"metadata":{"id":"LeEoQPVep5Lh"}},{"cell_type":"code","source":["df = df.dropna()"],"metadata":{"id":"FivH37uMp7VF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tiền xử lý bộ dữ liệu:\n","Dữ liệu đầu vào của chúng ta lúc này hiện đang ở dạng văn bản (string), chưa có đặc trưng rõ ràng cũng như không thể đưa vào huấn luyện mô hình được. Vì vậy, chúng ta sẽ tiền xử lý dữ liệu văn bản đầu vào để đưa về một dạng\n","vector đặc trưng nào đó:"],"metadata":{"id":"RJKWHtmaqATw"}},{"cell_type":"markdown","source":["### (a) Xây dựng hàm chuẩn hóa văn bản:\n","Văn bản gốc có rất nhiều kí tự dư thừa, vô nghĩa... Vì vậy, ta cần loại bỏ chúng cũng như áp dụng thêm vài bước chuẩn hóa văn bản khác để văn bản đầu vào trở nên ít phức tạp hơn, nhằm tăng cường hiệu quả biểu diễn của vector đặc trưng sau này:"],"metadata":{"id":"2dZ3BRleqDiA"}},{"cell_type":"code","source":["def text_normalize(text):\n","    # Lowercasing\n","    text = text.lower()\n","\n","    # Retweet old acronym \"RT\" removal\n","    text = re.sub(r'^rt[\\s]+', '', text)\n","\n","    # Hyperlinks removal\n","    text = re.sub(r'https?:\\/\\/.*[\\ r\\n]*', '', text)\n","\n","    # Punctuation removal\n","    text = re.sub(r'[^\\ w\\s]', '', text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","\n","    words = text.split()\n","    words = [word for word in words if word not in stop_words]\n","    text = ' '.join(words)\n","\n","    # Stemming\n","    stemmer = SnowballStemmer ('english')\n","    words = text.split()\n","    words = [stemmer.stem(word) for word in words]\n","    text = ' '.join(words)\n","\n","    return text"],"metadata":{"id":"8vg2tWJyqKBg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (b) Khởi tạo tf-idf vectorizer:\n","Trong bài này, chúng ta sẽ sử dụng một dạng vector biểu diễn đặc trưng mới cho văn bản, đó là tf-idf. Trong phạm vi của bài, chúng ta sẽ không đi sâu vào kỹ thuật tf-idf, các bạn có thể đọc thêm về kỹ thuật này tại [đây](https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/). Code biến đổi văn bản đầu vào thành vector tf-idf như sau:"],"metadata":{"id":"6aI2wr8rrB6h"}},{"cell_type":"code","source":["vectorizer = TfidfVectorizer(max_features=2000)\n","X = vectorizer.fit_transform(df['clean_text']).toarray()"],"metadata":{"id":"dfhdUWx6rQ3X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (c) Thêm bias vào X:"],"metadata":{"id":"E8Kz77Ltrs_f"}},{"cell_type":"code","source":["intercept = np.ones((X.shape[0], 1))\n","X_b = np.concatenate((intercept,X), axis=1)"],"metadata":{"id":"gMB8Rl9gry0L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## One-hot encoding label:"],"metadata":{"id":"RBRb6oU3r5i9"}},{"cell_type":"code","source":["n_classes = df['category'].nunique()\n","n_samples = df['category'].size\n","\n","y = df['category'].to_numpy() + 1\n","y = y.astype(np.uint8)\n","y_encoded = np.array([np.zeros(n_classes) for _ in range(n_samples)])\n","y_encoded[np.arange(n_samples), y] = 1"],"metadata":{"id":"Lb7YaF8cr7fb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Chia bộ train, val, test:"],"metadata":{"id":"aPlBN67xsqYS"}},{"cell_type":"code","source":["val_size = 0.2\n","test_size = 0.125\n","random_state = 2\n","is_shuffle = True\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_b, y_encoded,\n","                                                  test_size=val_size,\n","                                                  random_state=random_state,\n","                                                  shuffle=is_shuffle)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n","                                                    test_size = test_size,\n","                                                    random_state = random_state,\n","                                                    shuffle = is_shuffle)"],"metadata":{"id":"uI1q3WV4sr2d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cài đặt các hàm quan trọng:"],"metadata":{"id":"5J8K6ShYsybg"}},{"cell_type":"code","source":["def softmax(z):\n","  exp_z = np.exp(z)\n","  return exp_z / exp_z.sum(axis=1)[:, None]\n","\n","def predict(X, theta):\n","  z = np.dot(X, theta)\n","  y_hat = softmax(z)\n","  return y_hat\n","\n","def compute_loss(y_hat, y):\n","  n = y.size\n","\n","  return round((-1 / n) * np.sum(y * np.log(y_hat)), 8)\n","\n","def compute_gradient(X, y, y_hat):\n","  n = y.size\n","\n","  return np.dot(X.T, (y_hat - y)) / n\n","\n","def update_theta(theta, gradient, lr):\n","  return theta - lr * gradient\n","\n","def compute_accuracy(X, y, theta):\n","  y_hat = predict(X, theta)\n","  acc = (np.argmax(y_hat, axis=1) == np.argmax(y, axis=1)).mean()\n","  return acc"],"metadata":{"id":"xfJtXt23s2P7","executionInfo":{"status":"ok","timestamp":1731420734659,"user_tz":-420,"elapsed":448,"user":{"displayName":"Anh Nguyen","userId":"14949101190369963696"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Khai báo các siêu tham số và khởi tạo weights: Trong bài này, vì số lượng mẫu\n","dữ liệu là rất lớn, ta có thể cân nhắc tăng số batch size lên để tăng tốc độ huấn luyện (ví dụ ở đây ta cài batch_size=n_samples)."],"metadata":{"id":"LK3V6yv-uJaG"}},{"cell_type":"code","source":["lr = 0.1\n","epochs = 200\n","batch_size = X_train.shape[0]\n","n_features = X_train.shape[1]\n","\n","np.random.seed(random_state)\n","theta = np.random.uniform(size=(n_features, n_classes))"],"metadata":{"id":"ekxMQVMPuLS8","executionInfo":{"status":"ok","timestamp":1731420870136,"user_tz":-420,"elapsed":371,"user":{"displayName":"Anh Nguyen","userId":"14949101190369963696"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Huấn luyện mô hình:"],"metadata":{"id":"LIbmueQBufX3"}},{"cell_type":"code","source":["train_accs = []\n","train_losses = []\n","val_accs = []\n","val_losses = []\n","\n","for epoch in range(epochs):\n","    train_batch_losses = []\n","    train_batch_accs = []\n","    val_batch_losses = []\n","    val_batch_accs = []\n","\n","    for i in range(0, X_train.shape[0], batch_size):\n","        X_i = X_train[i:i+batch_size]\n","        y_i = y_train[i:i+batch_size]\n","\n","        y_hat = predict(X_i, theta)\n","        train_loss = compute_loss(y_hat, y_i)\n","\n","        gradient = compute_gradient(X_i, y_i, y_hat)\n","        theta = update_theta(theta, gradient, lr)\n","\n","        train_batch_losses.append(train_loss)\n","\n","        train_acc = compute_accuracy(X_train, y_train, theta)\n","        train_batch_accs.append(train_acc)\n","\n","        y_val_hat = predict(X_val, theta)\n","        val_loss = compute_loss(y_val_hat, y_val)\n","        val_batch_losses.append(val_loss)\n","\n","\n","        val_acc = compute_accuracy(X_val, y_val, theta)\n","        val_batch_accs.append(val_acc)\n","\n","    train_batch_loss = sum(train_batch_losses)/len(train_batch_losses)\n","    val_batch_loss = sum(val_batch_losses)/len(val_batch_losses)\n","    train_batch_acc = sum(train_batch_accs)/len(train_batch_accs)\n","    val_batch_acc = sum(val_batch_accs)/len(val_batch_accs)\n","\n","    train_losses.append(train_batch_loss)\n","    val_losses.append(val_batch_loss)\n","    train_accs.append(train_batch_acc)\n","    val_accs.append(val_batch_acc)\n","\n","    print (f'\\nEPOCH {epoch + 1}:\\tTraining loss : {train_batch_loss:.3f} \\tValidation loss : {val_batch_loss:.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rml-d9E6uger","executionInfo":{"status":"ok","timestamp":1731421104081,"user_tz":-420,"elapsed":206045,"user":{"displayName":"Anh Nguyen","userId":"14949101190369963696"}},"outputId":"cfa44837-5229-48c0-e56d-6e87dd6e5e9a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","EPOCH 1:\tTraining loss : 0.385 \tValidation loss : 0.384\n","\n","EPOCH 2:\tTraining loss : 0.385 \tValidation loss : 0.384\n","\n","EPOCH 3:\tTraining loss : 0.384 \tValidation loss : 0.383\n","\n","EPOCH 4:\tTraining loss : 0.384 \tValidation loss : 0.383\n","\n","EPOCH 5:\tTraining loss : 0.383 \tValidation loss : 0.382\n","\n","EPOCH 6:\tTraining loss : 0.383 \tValidation loss : 0.382\n","\n","EPOCH 7:\tTraining loss : 0.383 \tValidation loss : 0.382\n","\n","EPOCH 8:\tTraining loss : 0.382 \tValidation loss : 0.381\n","\n","EPOCH 9:\tTraining loss : 0.382 \tValidation loss : 0.381\n","\n","EPOCH 10:\tTraining loss : 0.382 \tValidation loss : 0.381\n","\n","EPOCH 11:\tTraining loss : 0.381 \tValidation loss : 0.380\n","\n","EPOCH 12:\tTraining loss : 0.381 \tValidation loss : 0.380\n","\n","EPOCH 13:\tTraining loss : 0.381 \tValidation loss : 0.380\n","\n","EPOCH 14:\tTraining loss : 0.380 \tValidation loss : 0.379\n","\n","EPOCH 15:\tTraining loss : 0.380 \tValidation loss : 0.379\n","\n","EPOCH 16:\tTraining loss : 0.380 \tValidation loss : 0.379\n","\n","EPOCH 17:\tTraining loss : 0.379 \tValidation loss : 0.378\n","\n","EPOCH 18:\tTraining loss : 0.379 \tValidation loss : 0.378\n","\n","EPOCH 19:\tTraining loss : 0.379 \tValidation loss : 0.378\n","\n","EPOCH 20:\tTraining loss : 0.379 \tValidation loss : 0.378\n","\n","EPOCH 21:\tTraining loss : 0.378 \tValidation loss : 0.377\n","\n","EPOCH 22:\tTraining loss : 0.378 \tValidation loss : 0.377\n","\n","EPOCH 23:\tTraining loss : 0.378 \tValidation loss : 0.377\n","\n","EPOCH 24:\tTraining loss : 0.378 \tValidation loss : 0.377\n","\n","EPOCH 25:\tTraining loss : 0.377 \tValidation loss : 0.376\n","\n","EPOCH 26:\tTraining loss : 0.377 \tValidation loss : 0.376\n","\n","EPOCH 27:\tTraining loss : 0.377 \tValidation loss : 0.376\n","\n","EPOCH 28:\tTraining loss : 0.377 \tValidation loss : 0.376\n","\n","EPOCH 29:\tTraining loss : 0.376 \tValidation loss : 0.375\n","\n","EPOCH 30:\tTraining loss : 0.376 \tValidation loss : 0.375\n","\n","EPOCH 31:\tTraining loss : 0.376 \tValidation loss : 0.375\n","\n","EPOCH 32:\tTraining loss : 0.376 \tValidation loss : 0.375\n","\n","EPOCH 33:\tTraining loss : 0.375 \tValidation loss : 0.375\n","\n","EPOCH 34:\tTraining loss : 0.375 \tValidation loss : 0.374\n","\n","EPOCH 35:\tTraining loss : 0.375 \tValidation loss : 0.374\n","\n","EPOCH 36:\tTraining loss : 0.375 \tValidation loss : 0.374\n","\n","EPOCH 37:\tTraining loss : 0.375 \tValidation loss : 0.374\n","\n","EPOCH 38:\tTraining loss : 0.374 \tValidation loss : 0.374\n","\n","EPOCH 39:\tTraining loss : 0.374 \tValidation loss : 0.373\n","\n","EPOCH 40:\tTraining loss : 0.374 \tValidation loss : 0.373\n","\n","EPOCH 41:\tTraining loss : 0.374 \tValidation loss : 0.373\n","\n","EPOCH 42:\tTraining loss : 0.374 \tValidation loss : 0.373\n","\n","EPOCH 43:\tTraining loss : 0.374 \tValidation loss : 0.373\n","\n","EPOCH 44:\tTraining loss : 0.373 \tValidation loss : 0.372\n","\n","EPOCH 45:\tTraining loss : 0.373 \tValidation loss : 0.372\n","\n","EPOCH 46:\tTraining loss : 0.373 \tValidation loss : 0.372\n","\n","EPOCH 47:\tTraining loss : 0.373 \tValidation loss : 0.372\n","\n","EPOCH 48:\tTraining loss : 0.373 \tValidation loss : 0.372\n","\n","EPOCH 49:\tTraining loss : 0.373 \tValidation loss : 0.372\n","\n","EPOCH 50:\tTraining loss : 0.372 \tValidation loss : 0.372\n","\n","EPOCH 51:\tTraining loss : 0.372 \tValidation loss : 0.371\n","\n","EPOCH 52:\tTraining loss : 0.372 \tValidation loss : 0.371\n","\n","EPOCH 53:\tTraining loss : 0.372 \tValidation loss : 0.371\n","\n","EPOCH 54:\tTraining loss : 0.372 \tValidation loss : 0.371\n","\n","EPOCH 55:\tTraining loss : 0.372 \tValidation loss : 0.371\n","\n","EPOCH 56:\tTraining loss : 0.372 \tValidation loss : 0.371\n","\n","EPOCH 57:\tTraining loss : 0.371 \tValidation loss : 0.371\n","\n","EPOCH 58:\tTraining loss : 0.371 \tValidation loss : 0.370\n","\n","EPOCH 59:\tTraining loss : 0.371 \tValidation loss : 0.370\n","\n","EPOCH 60:\tTraining loss : 0.371 \tValidation loss : 0.370\n","\n","EPOCH 61:\tTraining loss : 0.371 \tValidation loss : 0.370\n","\n","EPOCH 62:\tTraining loss : 0.371 \tValidation loss : 0.370\n","\n","EPOCH 63:\tTraining loss : 0.371 \tValidation loss : 0.370\n","\n","EPOCH 64:\tTraining loss : 0.371 \tValidation loss : 0.370\n","\n","EPOCH 65:\tTraining loss : 0.370 \tValidation loss : 0.370\n","\n","EPOCH 66:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 67:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 68:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 69:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 70:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 71:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 72:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 73:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 74:\tTraining loss : 0.370 \tValidation loss : 0.369\n","\n","EPOCH 75:\tTraining loss : 0.369 \tValidation loss : 0.369\n","\n","EPOCH 76:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 77:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 78:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 79:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 80:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 81:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 82:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 83:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 84:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 85:\tTraining loss : 0.369 \tValidation loss : 0.368\n","\n","EPOCH 86:\tTraining loss : 0.368 \tValidation loss : 0.368\n","\n","EPOCH 87:\tTraining loss : 0.368 \tValidation loss : 0.368\n","\n","EPOCH 88:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 89:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 90:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 91:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 92:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 93:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 94:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 95:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 96:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 97:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 98:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 99:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 100:\tTraining loss : 0.368 \tValidation loss : 0.367\n","\n","EPOCH 101:\tTraining loss : 0.367 \tValidation loss : 0.367\n","\n","EPOCH 102:\tTraining loss : 0.367 \tValidation loss : 0.367\n","\n","EPOCH 103:\tTraining loss : 0.367 \tValidation loss : 0.367\n","\n","EPOCH 104:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 105:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 106:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 107:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 108:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 109:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 110:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 111:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 112:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 113:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 114:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 115:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 116:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 117:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 118:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 119:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 120:\tTraining loss : 0.367 \tValidation loss : 0.366\n","\n","EPOCH 121:\tTraining loss : 0.366 \tValidation loss : 0.366\n","\n","EPOCH 122:\tTraining loss : 0.366 \tValidation loss : 0.366\n","\n","EPOCH 123:\tTraining loss : 0.366 \tValidation loss : 0.366\n","\n","EPOCH 124:\tTraining loss : 0.366 \tValidation loss : 0.366\n","\n","EPOCH 125:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 126:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 127:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 128:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 129:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 130:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 131:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 132:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 133:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 134:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 135:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 136:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 137:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 138:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 139:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 140:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 141:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 142:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 143:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 144:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 145:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 146:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 147:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 148:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 149:\tTraining loss : 0.366 \tValidation loss : 0.365\n","\n","EPOCH 150:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 151:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 152:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 153:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 154:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 155:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 156:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 157:\tTraining loss : 0.365 \tValidation loss : 0.365\n","\n","EPOCH 158:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 159:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 160:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 161:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 162:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 163:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 164:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 165:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 166:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 167:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 168:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 169:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 170:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 171:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 172:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 173:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 174:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 175:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 176:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 177:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 178:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 179:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 180:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 181:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 182:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 183:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 184:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 185:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 186:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 187:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 188:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 189:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 190:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 191:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 192:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 193:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 194:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 195:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 196:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 197:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 198:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 199:\tTraining loss : 0.365 \tValidation loss : 0.364\n","\n","EPOCH 200:\tTraining loss : 0.365 \tValidation loss : 0.364\n"]}]},{"cell_type":"code","source":["fig,ax = plt.subplots(2, 2, figsize=(12, 10))\n","ax[0, 0].plot(train_losses)\n","ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n","ax[0, 0].set_title('Training Loss')\n","\n","ax[0, 1].plot(val_losses, 'orange')\n","ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n","ax[0, 1].set_title('Validation Loss')\n","\n","ax[1, 0].plot(train_accs)\n","ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n","ax[1, 0].set_title('Training Accuracy')\n","\n","ax[1, 1].plot(val_accs, 'orange')\n","ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n","ax[1, 1].set_title ('Validation Accuracy')\n","\n","plt.show()"],"metadata":{"id":"jFbaabbjulNM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Đánh giá mô hình:"],"metadata":{"id":"3KxWWSUgus_X"}},{"cell_type":"code","source":["val_set_acc = compute_accuracy(X_val, y_val, theta)\n","test_set_acc = compute_accuracy(X_test, y_test, theta)\n","print('Evaluation on validation and test set :')\n","print(f'Accuracy : {val_set_acc}')\n","print(f'Accuracy : {test_set_acc}')"],"metadata":{"id":"zIs_W-q4uuGD"},"execution_count":null,"outputs":[]}]}